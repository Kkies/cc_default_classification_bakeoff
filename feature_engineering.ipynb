{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Classification Modeling\n",
    "The goal of this week's assessment is to find the model which best predicts whether or not a person will default on their bank loan. In doing so, we want to utilize all of the different tools we have learned over the course: data cleaning, EDA, feature engineering/transformation, feature selection, hyperparameter tuning, and model evaluation. \n",
    "\n",
    "\n",
    "#### Data Set Information:\n",
    "\n",
    "This research aimed at the case of customers default payments in Taiwan and compares the predictive accuracy of probability of default among six data mining methods. From the perspective of risk management, the result of predictive accuracy of the estimated probability of default will be more valuable than the binary result of classification - credible or not credible clients. Because the real probability of default is unknown, this study presented the novel Sorting Smoothing Method to estimate the real probability of default. With the real probability of default as the response variable (Y), and the predictive probability of default as the independent variable (X), the simple linear regression result (Y = A + BX) shows that the forecasting model produced by artificial neural network has the highest coefficient of determination; its regression intercept (A) is close to zero, and regression coefficient (B) to one. Therefore, among the six data mining techniques, artificial neural network is the only one that can accurately estimate the real probability of default. \n",
    "\n",
    "- NT is the abbreviation for New Taiwain. \n",
    "\n",
    "\n",
    "#### Attribute Information:\n",
    "\n",
    "This research employed a binary variable, default payment (Yes = 1, No = 0), as the response variable. This study reviewed the literature and used the following 23 variables as explanatory variables: \n",
    "- X1: Amount of the given credit (NT dollar): it includes both the individual consumer credit and his/her family (supplementary) credit. \n",
    "- X2: Gender (1 = male; 2 = female). \n",
    "- X3: Education (1 = graduate school; 2 = university; 3 = high school; 4 = others). \n",
    "- X4: Marital status (1 = married; 2 = single; 3 = others). \n",
    "- X5: Age (year). \n",
    "- X6 - X11: History of past payment. We tracked the past monthly payment records (from April to September, 2005) as follows: \n",
    "    - X6 = the repayment status in September, 2005; \n",
    "    - X7 = the repayment status in August, 2005; . . .;\n",
    "    - etc...\n",
    "    - X11 = the repayment status in April, 2005. \n",
    "    - The measurement scale for the repayment status is: -1 = pay duly; 1 = payment delay for one month; 2 = payment delay for two months; . . .; 8 = payment delay for eight months; 9 = payment delay for nine months and above. \n",
    "- X12-X17: Amount of bill statement (NT dollar). \n",
    "    - X12 = amount of bill statement in September, 2005;\n",
    "    - etc...\n",
    "    - X13 = amount of bill statement in August, 2005; . . .; \n",
    "    - X17 = amount of bill statement in April, 2005. \n",
    "- X18-X23: Amount of previous payment (NT dollar). \n",
    "    - X18 = amount paid in September, 2005; \n",
    "    - X19 = amount paid in August, 2005; . . .;\n",
    "    - etc...\n",
    "    - X23 = amount paid in April, 2005. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "You will fit three different models (KNN, Logistic Regression, and Decision Tree Classifier) to predict credit card defaults and use gridsearch to find the best hyperparameters for those models. Then you will compare the performance of those three models on a test set to find the best one.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process/Expectations\n",
    "\n",
    "- You will be working in pairs for this assessment\n",
    "\n",
    "### Please have ONE notebook and be prepared to explain how you worked in your pair.\n",
    "\n",
    "1. Clean up your data set so that you can perform an EDA. \n",
    "    - This includes handling null values, categorical variables, removing unimportant columns, and removing outliers.\n",
    "2. Perform EDA to identify opportunities to create new features.\n",
    "    - [Great Example of EDA for classification](https://www.kaggle.com/stephaniestallworth/titanic-eda-classification-end-to-end) \n",
    "    - [Using Pairplots with Classification](https://towardsdatascience.com/visualizing-data-with-pair-plots-in-python-f228cf529166)\n",
    "3. Engineer new features. \n",
    "    - Create polynomial and/or interaction features. \n",
    "    - Additionaly, you must also create **at least 2 new features** that are not interactions or polynomial transformations. \n",
    "        - *For example, you can create a new dummy variable that based on the value of a continuous variable (billamount6 >2000) or take the average of some past amounts.*\n",
    "4. Perform some feature selection. \n",
    "    \n",
    "5. You must fit **three** models to your data and tune **at least 1 hyperparameter** per model. \n",
    "6. Using the F-1 Score, evaluate how well your models perform and identify your best model.\n",
    "7. Using information from your EDA process and your model(s) output provide insight as to which borrowers are more likely to deafult\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('training_data.csv' , index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                             17471\n",
       "1                              5028\n",
       "default payment next month        1\n",
       "Name: Y, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>X11</th>\n",
       "      <th>X12</th>\n",
       "      <th>X13</th>\n",
       "      <th>X14</th>\n",
       "      <th>X15</th>\n",
       "      <th>X16</th>\n",
       "      <th>X17</th>\n",
       "      <th>X18</th>\n",
       "      <th>X19</th>\n",
       "      <th>X20</th>\n",
       "      <th>X21</th>\n",
       "      <th>X22</th>\n",
       "      <th>X23</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28835</th>\n",
       "      <td>220000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>222598</td>\n",
       "      <td>222168</td>\n",
       "      <td>217900</td>\n",
       "      <td>221193</td>\n",
       "      <td>181859</td>\n",
       "      <td>184605</td>\n",
       "      <td>10000</td>\n",
       "      <td>8018</td>\n",
       "      <td>10121</td>\n",
       "      <td>6006</td>\n",
       "      <td>10987</td>\n",
       "      <td>143779</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25329</th>\n",
       "      <td>200000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>326</td>\n",
       "      <td>326</td>\n",
       "      <td>326</td>\n",
       "      <td>326</td>\n",
       "      <td>326</td>\n",
       "      <td>326</td>\n",
       "      <td>326</td>\n",
       "      <td>326</td>\n",
       "      <td>326</td>\n",
       "      <td>326</td>\n",
       "      <td>326</td>\n",
       "      <td>326</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18894</th>\n",
       "      <td>180000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>80000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51372</td>\n",
       "      <td>51872</td>\n",
       "      <td>47593</td>\n",
       "      <td>43882</td>\n",
       "      <td>42256</td>\n",
       "      <td>42527</td>\n",
       "      <td>1853</td>\n",
       "      <td>1700</td>\n",
       "      <td>1522</td>\n",
       "      <td>1548</td>\n",
       "      <td>1488</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6239</th>\n",
       "      <td>10000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8257</td>\n",
       "      <td>7995</td>\n",
       "      <td>4878</td>\n",
       "      <td>5444</td>\n",
       "      <td>2639</td>\n",
       "      <td>2697</td>\n",
       "      <td>2000</td>\n",
       "      <td>1100</td>\n",
       "      <td>600</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           X1 X2 X3 X4  X5  X6  X7  X8  X9 X10 X11     X12     X13     X14  \\\n",
       "28835  220000  2  1  2  36   0   0   0   0   0   0  222598  222168  217900   \n",
       "25329  200000  2  3  2  29  -1  -1  -1  -1  -1  -1     326     326     326   \n",
       "18894  180000  2  1  2  27  -2  -2  -2  -2  -2  -2       0       0       0   \n",
       "690     80000  1  2  2  32   0   0   0   0   0   0   51372   51872   47593   \n",
       "6239    10000  1  2  2  27   0   0   0   0   0   0    8257    7995    4878   \n",
       "\n",
       "          X15     X16     X17    X18   X19    X20   X21    X22     X23  Y  \n",
       "28835  221193  181859  184605  10000  8018  10121  6006  10987  143779  1  \n",
       "25329     326     326     326    326   326    326   326    326     326  0  \n",
       "18894       0       0       0      0     0      0     0      0       0  0  \n",
       "690     43882   42256   42527   1853  1700   1522  1548   1488    1500  0  \n",
       "6239     5444    2639    2697   2000  1100    600   300    300    1000  1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28835     0\n",
       "25329    -1\n",
       "18894    -2\n",
       "690       0\n",
       "6239      0\n",
       "         ..\n",
       "16247     0\n",
       "2693     -1\n",
       "8076      1\n",
       "20213    -1\n",
       "7624      1\n",
       "Name: X6, Length: 22500, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['X6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "X1     object\n",
       "X2     object\n",
       "X3     object\n",
       "X4     object\n",
       "X5     object\n",
       "X6     object\n",
       "X7     object\n",
       "X8     object\n",
       "X9     object\n",
       "X10    object\n",
       "X11    object\n",
       "X12    object\n",
       "X13    object\n",
       "X14    object\n",
       "X15    object\n",
       "X16    object\n",
       "X17    object\n",
       "X18    object\n",
       "X19    object\n",
       "X20    object\n",
       "X21    object\n",
       "X22    object\n",
       "X23    object\n",
       "Y      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2            10516\n",
       "1             7919\n",
       "3             3713\n",
       "5              208\n",
       "4               90\n",
       "6               42\n",
       "0               11\n",
       "EDUCATION        1\n",
       "Name: X3, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['X3'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('ID', axis = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.apply(lambda x: x.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data to be used in the models\n",
    "# Create matrix of features\n",
    "X = df.drop('Y', axis = 1) # grabs everything else but 'Survived'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create target variable\n",
    "y = df['Y'] # y is the column we're trying to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "X4\n",
       "0.0    37.590909\n",
       "1.0    40.027857\n",
       "2.0    31.412606\n",
       "3.0    42.893162\n",
       "Name: X5, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## For our Marital Status column, we have 3 groups in our key but 4 in the dataframe\n",
    "## We need to figure out where 0 belongs\n",
    "\n",
    "## ! is married, 2 is single, 3 is others\n",
    "\n",
    "df.groupby('X4')['X5'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 0 appears to belong to 1 aka the married group but I should investigate further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "X4\n",
       "0.0    140681.818182\n",
       "1.0    181372.437469\n",
       "2.0    156242.115417\n",
       "3.0    103888.888889\n",
       "Name: X1, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('X4')['X1'].mean()\n",
    "\n",
    "## We have 4 groups in our key for Education Level but 7 in our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "X3\n",
       "0.0    40.545455\n",
       "1.0    34.231847\n",
       "2.0    34.658806\n",
       "3.0    40.157285\n",
       "4.0    34.666667\n",
       "5.0    35.937500\n",
       "6.0    43.904762\n",
       "Name: X5, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('X3')['X5'].mean()\n",
    "\n",
    "##6 and 0 look like they belong to 3 aka high school education\n",
    "## 5 might belong to 2 aka college education but I should investigate further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "X3\n",
       "0.0    220000.000000\n",
       "1.0    213389.316833\n",
       "2.0    146419.360974\n",
       "3.0    125641.712901\n",
       "4.0    230000.000000\n",
       "5.0    161951.923077\n",
       "6.0    135000.000000\n",
       "Name: X1, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('X3')['X1'].mean()\n",
    "\n",
    "## 1 graduate, 2 college, 3 high school, 4 others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28835    1.0\n",
       "25329    3.0\n",
       "18894    1.0\n",
       "690      2.0\n",
       "6239     2.0\n",
       "        ... \n",
       "16247    2.0\n",
       "2693     1.0\n",
       "8076     3.0\n",
       "20213    3.0\n",
       "7624     1.0\n",
       "Name: X3, Length: 22499, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['X3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    139\n",
       "2.0    117\n",
       "3.0      5\n",
       "Name: X4, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['X3'] == 5) | (df['X3'] == 6) | (df['X3'] == 0)]['X4'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.59090909090909"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['X4'] == 0]['X5'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\n",
    "    df['X3'].eq(0),\n",
    "    df['X3'].eq(1),\n",
    "    df['X3'].eq(2),\n",
    "    df['X3'].eq(3),\n",
    "    df['X3'].eq(4),\n",
    "    df['X3'].eq(5),\n",
    "    df['X3'].eq(6),\n",
    "]\n",
    "\n",
    "choices = [\n",
    "    0,\n",
    "    0,\n",
    "    0,\n",
    "    0,\n",
    "    0,\n",
    "    1,\n",
    "    1,   \n",
    "]\n",
    "\n",
    "df['X3_undefined'] = np.select(conditions,choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    22249\n",
       "1      250\n",
       "Name: X3_undefined, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['X3_undefined'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\n",
    "    df['X3'].eq(5),\n",
    "    df['X3'].eq(6)\n",
    "]\n",
    "\n",
    "choices = [\n",
    "    0,\n",
    "    0  \n",
    "]\n",
    "\n",
    "df['X3'] = np.select(conditions,choices, default = df['X3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0    10516\n",
       "1.0     7919\n",
       "3.0     3713\n",
       "0.0      261\n",
       "4.0       90\n",
       "Name: X3, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['X3'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0    12026\n",
       "1.0    10195\n",
       "3.0      234\n",
       "0.0       44\n",
       "Name: X4, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['X4'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['X4_undefined'] = np.where(df['X4'] == 0, 1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    22455\n",
       "1       44\n",
       "Name: X4_undefined, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['X4_undefined'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\n",
    "    df['X4'].eq(0)\n",
    "]\n",
    "\n",
    "choices = [\n",
    "    3\n",
    "]\n",
    "\n",
    "df['X4'] = np.select(conditions,choices, default = df['X4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0    12026\n",
       "1.0    10195\n",
       "3.0      278\n",
       "Name: X4, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['X4'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remaining balances after each monthly payment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bal_september'] = df['X12'] - df['X18'] #amount left to pay September\n",
    "df['bal_august'] = df['X13'] - df['X19'] #amount left to pay August\n",
    "df['bal_july'] = df['X14'] - df['X20'] #amount left to pay July\n",
    "df['bal_june'] = df['X15'] - df['X21'] #amount left to pay June\n",
    "df['bal_may'] = df['X16'] - df['X22'] #amount left to pay July\n",
    "df['bal_april'] = df['X17'] - df['X23'] #amount left to pay April"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monthly credit utilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['util_september'] = df['bal_september'] / df['X1'] #September credit utilization\n",
    "df['util_august'] = df['bal_august'] / df['X1'] #August credit utilization\n",
    "df['util_july'] = df['bal_july'] / df['X1'] #July credit utilization\n",
    "df['util_june'] = df['bal_june'] / df['X1'] #June credit utilization\n",
    "df['util_may'] = df['bal_may'] / df['X1'] #July credit utilization\n",
    "df['util_april'] = df['bal_april'] / df['X1'] #April credit utilization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilization Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test = [0.12,0.23,0.34,0.45,0.6]\n",
    "# test = [0.6, 0.5, 0.54, 0.2, 0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index, i in enumerate(test):\n",
    "#     if index == 0:\n",
    "#         trend = 0\n",
    "#     else:\n",
    "#         trend += i - test[index - 1]\n",
    "# trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def util_trend(df,cols):\n",
    "    for index, i in enumerate(cols):\n",
    "        if index == 0:\n",
    "            trend = 0\n",
    "        else:\n",
    "            trend += df[i] - df[cols[index - 1]]\n",
    "    return trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = ['util']\n",
    "months = ['september', 'august', 'july', 'june', 'may', 'april']\n",
    "i = [prefix[0] + \"_\" + x for x in months]\n",
    "df['util_trend'] = util_trend(df, i) #the overall trend of the credit utlization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['util_september',\n",
       " 'util_august',\n",
       " 'util_july',\n",
       " 'util_june',\n",
       " 'util_may',\n",
       " 'util_april']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Utilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['avg_util'] = (df[i[0]] + df[i[1]] + df[i[2]] + df[i[3]] + df[i[4]] + df[i[5]]) / 6 #average credit utilization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Payment History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['payment_hist'] = df.apply(lambda x:[x['X6'], x['X7'], x['X8'], x['X9'], x['X10'], x['X11']], axis = 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "looks like -2 is a value but i don't know what that means. Maybe they prepaid? Also, you can't be two months behind when you were up to date the month before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to Kaggle this is a possible interpretation:\n",
    "\n",
    "-2 = Balance paid in full and no transactions this period (we may refer to this credit card account as having been 'inactive' this period)\n",
    "\n",
    "-1 = Balance paid in full, but account has a positive balance at end of period due to recent transactions for which payment has not yet come due\n",
    "\n",
    "0 = Customer paid the minimum due amount, but not the entire balance. I.e., the customer paid enough for their account to remain in good standing, but did revolve a balance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Account Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['account_status'] = df['payment_hist'].apply(lambda lst:1 if max(set(lst), key=lst.count) > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 = bad standing, payments are not up to date for a majority of the time 0 = good standing the majority of time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ever owed more than thier credit limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['excess_debt'] = 1 * df.apply(lambda x: x['X12':'X17'] > x['X1'], axis = 1).any(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    19600\n",
       "1     2899\n",
       "Name: excess_debt, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['excess_debt'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continually owed more than thier credit limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['consistent_excess_debt'] = 1 * (df.apply(lambda x: x['X12':'X17'] > x['X1'], axis = 1).sum(axis = 1) > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    20931\n",
       "1     1568\n",
       "Name: consistent_excess_debt, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['consistent_excess_debt'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>X11</th>\n",
       "      <th>X12</th>\n",
       "      <th>X13</th>\n",
       "      <th>X14</th>\n",
       "      <th>X15</th>\n",
       "      <th>X16</th>\n",
       "      <th>X17</th>\n",
       "      <th>X18</th>\n",
       "      <th>X19</th>\n",
       "      <th>X20</th>\n",
       "      <th>X21</th>\n",
       "      <th>X22</th>\n",
       "      <th>X23</th>\n",
       "      <th>Y</th>\n",
       "      <th>X3_undefined</th>\n",
       "      <th>X4_undefined</th>\n",
       "      <th>bal_september</th>\n",
       "      <th>bal_august</th>\n",
       "      <th>bal_july</th>\n",
       "      <th>bal_june</th>\n",
       "      <th>bal_may</th>\n",
       "      <th>bal_april</th>\n",
       "      <th>util_september</th>\n",
       "      <th>util_august</th>\n",
       "      <th>util_july</th>\n",
       "      <th>util_june</th>\n",
       "      <th>util_may</th>\n",
       "      <th>util_april</th>\n",
       "      <th>util_trend</th>\n",
       "      <th>avg_util</th>\n",
       "      <th>payment_hist</th>\n",
       "      <th>account_status</th>\n",
       "      <th>excess_debt</th>\n",
       "      <th>consistent_excess_debt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28835</th>\n",
       "      <td>220000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>222598.0</td>\n",
       "      <td>222168.0</td>\n",
       "      <td>217900.0</td>\n",
       "      <td>221193.0</td>\n",
       "      <td>181859.0</td>\n",
       "      <td>184605.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>8018.0</td>\n",
       "      <td>10121.0</td>\n",
       "      <td>6006.0</td>\n",
       "      <td>10987.0</td>\n",
       "      <td>143779.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>212598.0</td>\n",
       "      <td>214150.0</td>\n",
       "      <td>207779.0</td>\n",
       "      <td>215187.0</td>\n",
       "      <td>170872.0</td>\n",
       "      <td>40826.0</td>\n",
       "      <td>0.966355</td>\n",
       "      <td>0.973409</td>\n",
       "      <td>0.944450</td>\n",
       "      <td>0.978123</td>\n",
       "      <td>0.776691</td>\n",
       "      <td>0.185573</td>\n",
       "      <td>-0.780782</td>\n",
       "      <td>0.804100</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25329</th>\n",
       "      <td>200000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18894</th>\n",
       "      <td>180000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[-2.0, -2.0, -2.0, -2.0, -2.0, -2.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>80000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51372.0</td>\n",
       "      <td>51872.0</td>\n",
       "      <td>47593.0</td>\n",
       "      <td>43882.0</td>\n",
       "      <td>42256.0</td>\n",
       "      <td>42527.0</td>\n",
       "      <td>1853.0</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>1522.0</td>\n",
       "      <td>1548.0</td>\n",
       "      <td>1488.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49519.0</td>\n",
       "      <td>50172.0</td>\n",
       "      <td>46071.0</td>\n",
       "      <td>42334.0</td>\n",
       "      <td>40768.0</td>\n",
       "      <td>41027.0</td>\n",
       "      <td>0.618988</td>\n",
       "      <td>0.627150</td>\n",
       "      <td>0.575887</td>\n",
       "      <td>0.529175</td>\n",
       "      <td>0.509600</td>\n",
       "      <td>0.512837</td>\n",
       "      <td>-0.106150</td>\n",
       "      <td>0.562273</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6239</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8257.0</td>\n",
       "      <td>7995.0</td>\n",
       "      <td>4878.0</td>\n",
       "      <td>5444.0</td>\n",
       "      <td>2639.0</td>\n",
       "      <td>2697.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6257.0</td>\n",
       "      <td>6895.0</td>\n",
       "      <td>4278.0</td>\n",
       "      <td>5144.0</td>\n",
       "      <td>2339.0</td>\n",
       "      <td>1697.0</td>\n",
       "      <td>0.625700</td>\n",
       "      <td>0.689500</td>\n",
       "      <td>0.427800</td>\n",
       "      <td>0.514400</td>\n",
       "      <td>0.233900</td>\n",
       "      <td>0.169700</td>\n",
       "      <td>-0.456000</td>\n",
       "      <td>0.443500</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             X1   X2   X3   X4    X5   X6   X7   X8   X9  X10  X11       X12  \\\n",
       "28835  220000.0  2.0  1.0  2.0  36.0  0.0  0.0  0.0  0.0  0.0  0.0  222598.0   \n",
       "25329  200000.0  2.0  3.0  2.0  29.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0     326.0   \n",
       "18894  180000.0  2.0  1.0  2.0  27.0 -2.0 -2.0 -2.0 -2.0 -2.0 -2.0       0.0   \n",
       "690     80000.0  1.0  2.0  2.0  32.0  0.0  0.0  0.0  0.0  0.0  0.0   51372.0   \n",
       "6239    10000.0  1.0  2.0  2.0  27.0  0.0  0.0  0.0  0.0  0.0  0.0    8257.0   \n",
       "\n",
       "            X13       X14       X15       X16       X17      X18     X19  \\\n",
       "28835  222168.0  217900.0  221193.0  181859.0  184605.0  10000.0  8018.0   \n",
       "25329     326.0     326.0     326.0     326.0     326.0    326.0   326.0   \n",
       "18894       0.0       0.0       0.0       0.0       0.0      0.0     0.0   \n",
       "690     51872.0   47593.0   43882.0   42256.0   42527.0   1853.0  1700.0   \n",
       "6239     7995.0    4878.0    5444.0    2639.0    2697.0   2000.0  1100.0   \n",
       "\n",
       "           X20     X21      X22       X23    Y  X3_undefined  X4_undefined  \\\n",
       "28835  10121.0  6006.0  10987.0  143779.0  1.0             0             0   \n",
       "25329    326.0   326.0    326.0     326.0  0.0             0             0   \n",
       "18894      0.0     0.0      0.0       0.0  0.0             0             0   \n",
       "690     1522.0  1548.0   1488.0    1500.0  0.0             0             0   \n",
       "6239     600.0   300.0    300.0    1000.0  1.0             0             0   \n",
       "\n",
       "       bal_september  bal_august  bal_july  bal_june   bal_may  bal_april  \\\n",
       "28835       212598.0    214150.0  207779.0  215187.0  170872.0    40826.0   \n",
       "25329            0.0         0.0       0.0       0.0       0.0        0.0   \n",
       "18894            0.0         0.0       0.0       0.0       0.0        0.0   \n",
       "690          49519.0     50172.0   46071.0   42334.0   40768.0    41027.0   \n",
       "6239          6257.0      6895.0    4278.0    5144.0    2339.0     1697.0   \n",
       "\n",
       "       util_september  util_august  util_july  util_june  util_may  \\\n",
       "28835        0.966355     0.973409   0.944450   0.978123  0.776691   \n",
       "25329        0.000000     0.000000   0.000000   0.000000  0.000000   \n",
       "18894        0.000000     0.000000   0.000000   0.000000  0.000000   \n",
       "690          0.618988     0.627150   0.575887   0.529175  0.509600   \n",
       "6239         0.625700     0.689500   0.427800   0.514400  0.233900   \n",
       "\n",
       "       util_april  util_trend  avg_util                          payment_hist  \\\n",
       "28835    0.185573   -0.780782  0.804100        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "25329    0.000000    0.000000  0.000000  [-1.0, -1.0, -1.0, -1.0, -1.0, -1.0]   \n",
       "18894    0.000000    0.000000  0.000000  [-2.0, -2.0, -2.0, -2.0, -2.0, -2.0]   \n",
       "690      0.512837   -0.106150  0.562273        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "6239     0.169700   -0.456000  0.443500        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "\n",
       "       account_status  excess_debt  consistent_excess_debt  \n",
       "28835               0            1                       1  \n",
       "25329               0            0                       0  \n",
       "18894               0            0                       0  \n",
       "690                 0            0                       0  \n",
       "6239                0            0                       0  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kbest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Fitting and Hyperparameter Tuning\n",
    "KNN, Logistic Regression, Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data to be used in the models\n",
    "# Create matrix of features\n",
    "X = df.drop(['Y', 'payment_hist'], axis = 1) # grabs everything else but 'Survived' is this suspoesed to be survived?\n",
    "\n",
    "\n",
    "# Create target variable\n",
    "y = df['Y'] # y is the column we're trying to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correct class imbalance\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm_base = SMOTE(random_state=27)\n",
    "X_train_base, y_train_base = sm_base.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    12204\n",
       "0.0    12204\n",
       "Name: Y, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_base.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_binary_cols = list(((X.max() > 1) | (X.min() < 0)).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only scale non binary columns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "base_ct = ColumnTransformer([\n",
    "        ('base_transform', StandardScaler(), non_binary_cols)\n",
    "    ], remainder='passthrough')\n",
    "\n",
    "base_ct.fit(X_train)\n",
    "X_train_base_scaled = pd.DataFrame(data=base_ct.transform(X_train), columns = X_train.columns)\n",
    "X_test_base_scaled = pd.DataFrame(data=base_ct.transform(X_test), columns = X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 1 epochs took 0 seconds\n",
      "convergence after 3 epochs took 0 secondsconvergence after 3 epochs took 0 seconds\n",
      "\n",
      "convergence after 3 epochs took 0 seconds\n",
      "convergence after 3 epochs took 0 seconds\n",
      "convergence after 3 epochs took 0 seconds\n",
      "convergence after 3 epochs took 0 seconds\n",
      "convergence after 4 epochs took 0 seconds\n",
      "convergence after 21 epochs took 0 seconds\n",
      "convergence after 22 epochs took 0 seconds\n",
      "convergence after 22 epochs took 0 seconds\n",
      "convergence after 22 epochs took 0 seconds\n",
      "convergence after 21 epochs took 0 seconds\n",
      "convergence after 22 epochs took 0 secondsconvergence after 21 epochs took 0 seconds\n",
      "\n",
      "convergence after 22 epochs took 0 seconds\n",
      "convergence after 25 epochs took 1 seconds\n",
      "convergence after 28 epochs took 1 seconds\n",
      "convergence after 31 epochs took 1 seconds\n",
      "convergence after 30 epochs took 1 seconds\n",
      "convergence after 31 epochs took 1 seconds\n",
      "convergence after 29 epochs took 1 seconds\n",
      "convergence after 32 epochs took 1 seconds\n",
      "convergence after 34 epochs took 1 seconds\n",
      "convergence after 134 epochs took 3 seconds\n",
      "convergence after 148 epochs took 3 seconds\n",
      "convergence after 135 epochs took 3 seconds\n",
      "convergence after 143 epochs took 3 seconds\n",
      "convergence after 149 epochs took 3 seconds\n",
      "convergence after 159 epochs took 4 seconds\n",
      "convergence after 180 epochs took 4 seconds\n",
      "convergence after 168 epochs took 4 seconds\n",
      "convergence after 532 epochs took 11 seconds\n",
      "convergence after 545 epochs took 12 seconds\n",
      "convergence after 145 epochs took 3 seconds\n",
      "convergence after 151 epochs took 3 seconds\n",
      "convergence after 44 epochs took 1 seconds\n",
      "convergence after 9 epochs took 0 seconds\n",
      "convergence after 2 epochs took 0 seconds\n",
      "convergence after 2 epochs took 0 seconds\n",
      "convergence after 46 epochs took 1 seconds\n",
      "convergence after 3 epochs took 0 seconds\n",
      "convergence after 9 epochs took 1 seconds\n",
      "convergence after 2 epochs took 0 seconds\n",
      "convergence after 2 epochs took 0 seconds\n",
      "convergence after 4 epochs took 0 seconds\n",
      "convergence after 21 epochs took 1 seconds\n",
      "convergence after 798 epochs took 17 seconds\n",
      "convergence after 22 epochs took 0 seconds\n",
      "convergence after 34 epochs took 1 seconds\n",
      "convergence after 29 epochs took 1 seconds\n",
      "convergence after 144 epochs took 3 seconds\n",
      "convergence after 897 epochs took 20 seconds\n",
      "convergence after 147 epochs took 3 seconds\n",
      "convergence after 47 epochs took 1 seconds\n",
      "convergence after 9 epochs took 0 seconds\n",
      "convergence after 2 epochs took 0 seconds\n",
      "convergence after 2 epochs took 0 seconds\n",
      "convergence after 179 epochs took 4 seconds\n",
      "convergence after 989 epochs took 22 seconds\n",
      "convergence after 150 epochs took 4 seconds\n",
      "convergence after 44 epochs took 1 seconds\n",
      "convergence after 9 epochs took 0 seconds\n",
      "convergence after 2 epochs took 0 seconds\n",
      "convergence after 2 epochs took 0 seconds\n",
      "convergence after 152 epochs took 4 seconds\n",
      "convergence after 1245 epochs took 26 seconds\n",
      "convergence after 43 epochs took 0 seconds\n",
      "convergence after 9 epochs took 1 seconds\n",
      "convergence after 2 epochs took 0 seconds\n",
      "convergence after 2 epochs took 0 seconds\n",
      "convergence after 149 epochs took 3 seconds\n",
      "convergence after 60 epochs took 0 seconds\n",
      "convergence after 10 epochs took 1 seconds\n",
      "convergence after 2 epochs took 0 seconds\n",
      "convergence after 2 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:   33.9s remaining:   22.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 1474 epochs took 30 seconds\n",
      "convergence after 678 epochs took 11 seconds\n",
      "convergence after 139 epochs took 2 seconds\n",
      "convergence after 51 epochs took 1 seconds\n",
      "convergence after 9 epochs took 0 seconds\n",
      "convergence after 2 epochs took 0 seconds\n",
      "convergence after 2 epochs took 0 seconds\n",
      "convergence after 138 epochs took 2 seconds\n",
      "convergence after 46 epochs took 1 seconds\n",
      "convergence after 9 epochs took 0 seconds\n",
      "convergence after 2 epochs took 0 seconds\n",
      "convergence after 2 epochs took 0 seconds\n",
      "convergence after 791 epochs took 13 seconds\n",
      "convergence after 151 epochs took 2 seconds\n",
      "convergence after 46 epochs took 0 seconds\n",
      "convergence after 9 epochs took 0 seconds\n",
      "convergence after 2 epochs took 0 seconds\n",
      "convergence after 2 epochs took 0 seconds\n",
      "convergence after 1952 epochs took 37 seconds\n",
      "convergence after 152 epochs took 2 seconds\n",
      "convergence after 49 epochs took 0 seconds\n",
      "convergence after 10 epochs took 1 seconds\n",
      "convergence after 2 epochs took 0 seconds\n",
      "convergence after 2 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   44.8s finished\n"
     ]
    }
   ],
   "source": [
    "# run logit with non polys\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "logreg = LogisticRegressionCV(cv = 10, penalty='l1', solver = 'saga', max_iter=10000, scoring='f1', n_jobs = -1, verbose = 1)\n",
    "logreg.fit(X_train_base_scaled, y_train_base)\n",
    "y_preds_base = logreg.predict(X_test_base_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6982222222222222\n",
      "precision: 0.3874898456539399\n",
      "recall: 0.6432906271072151\n",
      "f1: 0.48365019011406846\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score\n",
    "acc_score_base = accuracy_score(y_test, y_preds_base)\n",
    "precision_base = precision_score(y_test, y_preds_base)\n",
    "recall_base = recall_score(y_test, y_preds_base)\n",
    "f1_base = f1_score(y_test, y_preds_base)\n",
    "\n",
    "print(f'accuracy: {acc_score_base}')\n",
    "print(f'precision: {precision_base}')\n",
    "print(f'recall: {recall_base}')\n",
    "print(f'f1: {f1_base}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('X1', -0.16765286704579035),\n",
       " ('X2', -0.04803066944960413),\n",
       " ('X3', -0.06704701987310553),\n",
       " ('X4', -0.08333860958276146),\n",
       " ('X5', 0.06284497630691871),\n",
       " ('X6', 0.6591200681542689),\n",
       " ('X7', 0.20811075886638378),\n",
       " ('X8', 0.026827199529193435),\n",
       " ('X9', 0.0),\n",
       " ('X10', 0.05418909326154573),\n",
       " ('X11', -0.07379616085060292),\n",
       " ('X12', -0.023640119782739978),\n",
       " ('X13', 0.0),\n",
       " ('X14', 0.0),\n",
       " ('X15', 0.0),\n",
       " ('X16', 0.0),\n",
       " ('X17', -0.032458617978538266),\n",
       " ('X18', -0.3154243416304572),\n",
       " ('X19', -0.2262765040571774),\n",
       " ('X20', -0.028664083016322353),\n",
       " ('X21', -0.06385284888335216),\n",
       " ('X22', -0.06209078135561669),\n",
       " ('X23', -0.03775450433576465),\n",
       " ('X3_undefined', -0.18409690888460653),\n",
       " ('X4_undefined', -0.06857126331034123),\n",
       " ('bal_september', 0.0),\n",
       " ('bal_august', 0.0),\n",
       " ('bal_july', 0.08329538039642931),\n",
       " ('bal_june', 0.0),\n",
       " ('bal_may', 0.0),\n",
       " ('bal_april', 0.0),\n",
       " ('util_september', -0.32638801012580715),\n",
       " ('util_august', 0.181671319985354),\n",
       " ('util_july', 0.0),\n",
       " ('util_june', 0.05452170099455451),\n",
       " ('util_may', 0.0),\n",
       " ('util_april', 0.0),\n",
       " ('util_trend', 0.04105869286958468),\n",
       " ('avg_util', 0.0),\n",
       " ('account_status', 0.025756897629463392),\n",
       " ('excess_debt', -0.04849860803636683),\n",
       " ('consistent_excess_debt', -0.05032827631362346)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(X.columns, logreg.coef_[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logit with Poly2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly2 = PolynomialFeatures(degree=2, include_bias=False, interaction_only = False)\n",
    "poly2_data = poly2.fit_transform(X)\n",
    "poly2_columns = poly2.get_feature_names(X.columns)\n",
    "X_poly2 = pd.DataFrame(poly2_data, columns=poly2_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_poly2, X_test_poly2, y_train_poly2, y_test_poly2 = train_test_split(X_poly2, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_poly2 = SMOTE(random_state=28)\n",
    "X_train_poly2, y_train_poly2 = sm_poly2.fit_sample(X_train_poly2, y_train_poly2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    12222\n",
       "0.0    12222\n",
       "Name: Y, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_poly2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_binary_cols_poly2 = list(((X_poly2.max() > 1) | (X_poly2.min() < 0)).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly2_ct = ColumnTransformer([\n",
    "        ('poly2_transform', StandardScaler(), non_binary_cols_poly2)\n",
    "    ], remainder='passthrough')\n",
    "\n",
    "poly2_ct.fit(X_train_poly2)\n",
    "X_train_poly2_scaled = pd.DataFrame(data=poly2_ct.transform(X_train_poly2), columns = X_train_poly2.columns)\n",
    "X_test_poly2_scaled = pd.DataFrame(data=poly2_ct.transform(X_test_poly2), columns = X_train_poly2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "945"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_poly2_scaled.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/krk/anaconda3/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:114: UserWarning: Features [146 756 790 791] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx,\n",
      "/Users/krk/anaconda3/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:116: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SelectKBest(k=190)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif, SelectFpr\n",
    "selector = SelectKBest(f_classif, k=190)\n",
    "\n",
    "selector.fit(X_train_poly2_scaled, y_train_poly2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = X_train_poly2_scaled.columns[selector.get_support()]\n",
    "removed_columns = X_train_poly2_scaled.columns[~selector.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['X1', 'X6', 'X7', 'X8', 'X9', 'X10', 'X11', 'util_april', 'avg_util',\n",
       "       'account_status',\n",
       "       ...\n",
       "       'bal_may account_status', 'bal_april account_status',\n",
       "       'util_september account_status', 'util_august account_status',\n",
       "       'util_july account_status', 'util_june account_status',\n",
       "       'util_may account_status', 'util_april account_status',\n",
       "       'avg_util account_status', 'account_status^2'],\n",
       "      dtype='object', length=200)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 1 epochs took 1 seconds\n",
      "convergence after 1 epochs took 1 seconds\n",
      "convergence after 1 epochs took 1 seconds\n",
      "convergence after 1 epochs took 1 seconds\n",
      "convergence after 3 epochs took 1 seconds\n",
      "convergence after 3 epochs took 1 seconds\n",
      "convergence after 3 epochs took 1 seconds\n",
      "convergence after 3 epochs took 1 seconds\n",
      "convergence after 249 epochs took 17 seconds\n",
      "convergence after 254 epochs took 18 seconds\n",
      "convergence after 252 epochs took 18 seconds\n",
      "convergence after 254 epochs took 18 seconds\n",
      "convergence after 263 epochs took 18 seconds\n",
      "convergence after 258 epochs took 18 seconds\n",
      "convergence after 259 epochs took 18 seconds\n",
      "convergence after 259 epochs took 18 seconds\n",
      "convergence after 201 epochs took 15 seconds\n",
      "convergence after 216 epochs took 15 seconds\n",
      "convergence after 222 epochs took 16 seconds\n",
      "convergence after 219 epochs took 16 seconds\n",
      "convergence after 234 epochs took 16 seconds\n",
      "convergence after 252 epochs took 18 seconds\n",
      "convergence after 250 epochs took 18 seconds\n",
      "convergence after 251 epochs took 19 seconds\n",
      "convergence after 294 epochs took 23 seconds\n",
      "convergence after 327 epochs took 25 seconds\n",
      "convergence after 315 epochs took 25 seconds\n",
      "convergence after 297 epochs took 24 seconds\n",
      "convergence after 275 epochs took 23 seconds\n",
      "convergence after 312 epochs took 26 seconds\n",
      "convergence after 293 epochs took 24 seconds\n",
      "convergence after 309 epochs took 26 seconds\n",
      "convergence after 107 epochs took 13 seconds\n",
      "convergence after 143 epochs took 17 seconds\n",
      "convergence after 122 epochs took 14 seconds\n",
      "convergence after 170 epochs took 20 seconds\n",
      "convergence after 154 epochs took 18 seconds\n",
      "convergence after 146 epochs took 17 seconds\n",
      "convergence after 59 epochs took 6 seconds\n",
      "convergence after 8 epochs took 1 seconds\n",
      "convergence after 2 epochs took 0 seconds\n",
      "convergence after 2 epochs took 0 seconds\n",
      "convergence after 2 epochs took 1 seconds\n",
      "convergence after 1 epochs took 0 seconds\n",
      "convergence after 59 epochs took 5 seconds\n",
      "convergence after 9 epochs took 1 seconds\n",
      "convergence after 219 epochs took 24 seconds\n",
      "convergence after 2 epochs took 0 seconds\n",
      "convergence after 54 epochs took 5 seconds\n",
      "convergence after 208 epochs took 23 seconds\n",
      "convergence after 2 epochs took 0 seconds\n",
      "convergence after 2 epochs took 1 seconds\n",
      "convergence after 8 epochs took 1 seconds\n",
      "convergence after 4 epochs took 0 seconds\n",
      "convergence after 2 epochs took 0 seconds\n",
      "convergence after 2 epochs took 0 seconds\n",
      "convergence after 2 epochs took 0 seconds\n",
      "convergence after 75 epochs took 7 seconds\n",
      "convergence after 10 epochs took 1 seconds\n",
      "convergence after 2 epochs took 0 seconds\n",
      "convergence after 79 epochs took 7 seconds\n",
      "convergence after 83 epochs took 7 seconds\n",
      "convergence after 2 epochs took 0 seconds\n",
      "convergence after 2 epochs took 0 seconds\n",
      "convergence after 14 epochs took 1 seconds\n",
      "convergence after 16 epochs took 1 seconds\n",
      "convergence after 2 epochs took 0 seconds\n",
      "convergence after 60 epochs took 5 seconds\n",
      "convergence after 2 epochs took 0 seconds\n",
      "convergence after 3 epochs took 0 seconds\n",
      "convergence after 2 epochs took 0 seconds\n",
      "convergence after 2 epochs took 1 seconds\n",
      "convergence after 2 epochs took 0 seconds\n",
      "convergence after 10 epochs took 1 seconds\n",
      "convergence after 70 epochs took 6 seconds\n",
      "convergence after 2 epochs took 0 seconds\n",
      "convergence after 2 epochs took 0 seconds\n",
      "convergence after 2 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:  1.5min remaining:   37.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 13 epochs took 1 seconds\n",
      "convergence after 2 epochs took 0 seconds\n",
      "convergence after 2 epochs took 0 seconds\n",
      "convergence after 2 epochs took 0 seconds\n",
      "convergence after 254 epochs took 13 seconds\n",
      "convergence after 258 epochs took 13 seconds\n",
      "convergence after 211 epochs took 9 seconds\n",
      "convergence after 255 epochs took 10 seconds\n",
      "convergence after 335 epochs took 13 seconds\n",
      "convergence after 271 epochs took 12 seconds\n",
      "convergence after 157 epochs took 7 seconds\n",
      "convergence after 169 epochs took 8 seconds\n",
      "convergence after 67 epochs took 3 seconds\n",
      "convergence after 9 epochs took 1 seconds\n",
      "convergence after 2 epochs took 0 seconds\n",
      "convergence after 2 epochs took 0 seconds\n",
      "convergence after 2 epochs took 0 seconds\n",
      "convergence after 67 epochs took 3 seconds\n",
      "convergence after 9 epochs took 0 seconds\n",
      "convergence after 2 epochs took 0 seconds\n",
      "convergence after 2 epochs took 0 seconds\n",
      "convergence after 2 epochs took 0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 31 epochs took 2 seconds\n"
     ]
    }
   ],
   "source": [
    "logreg_poly2 = LogisticRegressionCV(cv = 10, penalty='l1', tol = 0.0007, solver = 'saga', max_iter=1000, scoring='f1', n_jobs = -1, verbose =2)\n",
    "logreg_poly2.fit(X_train_poly2_scaled[selected_columns], y_train_poly2)\n",
    "y_preds_poly2 = logreg_poly2.predict(X_test_poly2_scaled[selected_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 386 epochs took 17 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:   17.7s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg_poly2_1 = LogisticRegression(C = 0.3, penalty='l1', tol = 0.0007, solver = 'saga', max_iter=1000, n_jobs = -1, verbose =2)\n",
    "logreg_poly2_1.fit(X_train_poly2_scaled[selected_columns], y_train_poly2)\n",
    "y_preds_poly2_1 = logreg_poly2_1.predict(X_test_poly2_scaled[selected_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7752592592592593\n",
      "precision: 0.49523809523809526\n",
      "recall: 0.5542971352431713\n",
      "f1: 0.5231059415278214\n"
     ]
    }
   ],
   "source": [
    "acc_score_poly2 = accuracy_score(y_test_poly2, y_preds_poly2)\n",
    "precision_poly2 = precision_score(y_test_poly2, y_preds_poly2)\n",
    "recall_poly2 = recall_score(y_test_poly2, y_preds_poly2)\n",
    "f1_poly2 = f1_score(y_test_poly2, y_preds_poly2)\n",
    "\n",
    "print(f'accuracy: {acc_score_poly2}')\n",
    "print(f'precision: {precision_poly2}')\n",
    "print(f'recall: {recall_poly2}')\n",
    "print(f'f1: {f1_poly2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7758518518518519\n",
      "precision: 0.4964114832535885\n",
      "recall: 0.5529646902065289\n",
      "f1: 0.5231641979199496\n"
     ]
    }
   ],
   "source": [
    "acc_score_poly2 = accuracy_score(y_test_poly2, y_preds_poly2_1)\n",
    "precision_poly2 = precision_score(y_test_poly2, y_preds_poly2_1)\n",
    "recall_poly2 = recall_score(y_test_poly2, y_preds_poly2_1)\n",
    "f1_poly2 = f1_score(y_test_poly2, y_preds_poly2_1)\n",
    "\n",
    "print(f'accuracy: {acc_score_poly2}')\n",
    "print(f'precision: {precision_poly2}')\n",
    "print(f'recall: {recall_poly2}')\n",
    "print(f'f1: {f1_poly2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_randfor, X_test_randfor, y_train_randfor, y_test_randfor = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "sm_randfor = SMOTE(random_state=29)\n",
    "X_train_randfor, y_train_randfor = sm_randfor.fit_sample(X_train_randfor, y_train_randfor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rand_for = RandomForestClassifier(max_depth=3, min_samples_leaf=25, max_features =10, random_state=30, oob_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=3, max_features=10, min_samples_leaf=25,\n",
       "                       oob_score=True, random_state=30)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_for.fit(X_train_randfor, y_train_randfor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_randfor = rand_for.predict(X_test_randfor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating our parameters to test\n",
    "param_dict={'max_features': range(10,80,10)}\n",
    "#            'min_samples_leaf' : range(10,20,1),\n",
    "#            'max_features': range(10,80,10)}\n",
    "#create the instance of GridSearchCV using the F1 metric for our scoring. \n",
    "grid_tree=GridSearchCV(rand_for, param_grid = param_dict, cv=8, scoring='f1', verbose = True, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 8 folds for each of 7 candidates, totalling 56 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done  56 out of  56 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=8, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'max_features': range(10, 80, 10)}, scoring='f1',\n",
       "             verbose=True)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the Gridsearch to our data\n",
    "grid_tree.fit(X_train_randfor, y_train_randfor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 10}"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_tree.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 6}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_tree.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 26, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 10}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_tree.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_randfor = grid_tree.best_estimator_.predict(X_test_randfor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.798074074074074\n",
      "precision: 0.5349500713266762\n",
      "recall: 0.5133470225872689\n",
      "f1: 0.5239259517988124\n"
     ]
    }
   ],
   "source": [
    "acc_score_randfor = accuracy_score(y_test_randfor, y_preds_randfor)\n",
    "precision_randfor = precision_score(y_test_randfor, y_preds_randfor)\n",
    "recall_randfor = recall_score(y_test_randfor, y_preds_randfor)\n",
    "f1_randfor = f1_score(y_test_randfor, y_preds_randfor)\n",
    "\n",
    "print(f'accuracy: {acc_score_randfor}')\n",
    "print(f'precision: {precision_randfor}')\n",
    "print(f'recall: {recall_randfor}')\n",
    "print(f'f1: {f1_randfor}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "voting = VotingClassifier(estimators=[('lr_base', logreg), ('lr_poly2', logreg_poly2), ('rand_for', rand_for)], voting = 'hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed: 46.1min remaining: 30.7min\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 68.6min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:  8.2min remaining:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 12.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 32 epochs took 6 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr_base',\n",
       "                              LogisticRegressionCV(cv=10, max_iter=10000,\n",
       "                                                   n_jobs=-1, penalty='l1',\n",
       "                                                   scoring='f1', solver='saga',\n",
       "                                                   verbose=1)),\n",
       "                             ('lr_poly2',\n",
       "                              LogisticRegressionCV(cv=10, max_iter=1000,\n",
       "                                                   n_jobs=-1, penalty='l1',\n",
       "                                                   scoring='f1', solver='saga',\n",
       "                                                   tol=0.0007, verbose=2)),\n",
       "                             ('rand_for',\n",
       "                              RandomForestClassifier(max_depth=3,\n",
       "                                                     max_features=10,\n",
       "                                                     min_samples_leaf=25,\n",
       "                                                     oob_score=True,\n",
       "                                                     random_state=30))])"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting.fit(X_train_poly2_scaled, y_train_poly2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_voting = voting.predict(X_test_poly2_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.7714074074074074\n",
      "precision: 0.48760330578512395\n",
      "recall: 0.5502998001332445\n",
      "f1: 0.5170579029733959\n"
     ]
    }
   ],
   "source": [
    "acc_score_voting = accuracy_score(y_test_poly2, y_preds_voting)\n",
    "precision_voting = precision_score(y_test_poly2, y_preds_voting)\n",
    "recall_voting = recall_score(y_test_poly2, y_preds_voting)\n",
    "f1_voting = f1_score(y_test_poly2, y_preds_voting)\n",
    "\n",
    "print(f'accuracy: {acc_score_voting}')\n",
    "print(f'precision: {precision_voting}')\n",
    "print(f'recall: {recall_voting}')\n",
    "print(f'f1: {f1_voting}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_preds = logreg.predict(X_test)\n",
    "# log_poly2_1_preds = logreg_poly2_1.predict(X_test)\n",
    "randfor_preds = rand_for.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds = 1 * (((log_preds + 2*randfor_preds) / 2) >= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8026666666666666\n",
      "precision: 0.5538132573057734\n",
      "recall: 0.523937963587323\n",
      "f1: 0.5384615384615384\n"
     ]
    }
   ],
   "source": [
    "acc_score_final = accuracy_score(y_test, final_preds)\n",
    "precision_final = precision_score(y_test, final_preds)\n",
    "recall_final = recall_score(y_test, final_preds)\n",
    "f1_final = f1_score(y_test, final_preds)\n",
    "\n",
    "print(f'accuracy: {acc_score_final}')\n",
    "print(f'precision: {precision_final}')\n",
    "print(f'recall: {recall_final}')\n",
    "print(f'f1: {f1_final}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
